{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Assignment 22.1: Part 1: Parallel Computing with Pandas, NumPy, and DASK\n",
    "\n",
    "### Learning Outcomes:\n",
    "- 2. Run parallel operations in DASK.\n",
    "\n",
    "## Assignment Overview\n",
    "\n",
    "In Part 1 of the final assignment, you will compare the performance of the pandas, NumPy, and DASK *libraries* when doing calculations. In the first part, you will be working with NumPy and DASK *arrays* to analyze which *library* is faster. Next, you will make the same comparison working with pandas and DASK *dataframes*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: NumPy vs. DASK\n",
    "\n",
    "In the first part of the assignment, you will compare the performance of the NumPy and DASK *libraries* when computing operations on a two-dimensional NumPy *array*.\n",
    "\n",
    "Run the code cell below to import the necessary *libraries* for this portion of the final assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.array as da\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "In the code cell below, fill in the ellipsis to create a two-dimensional NumPy *array*, `arr`, with entries from 1 to 1,000 and dimensions 2,000 by 2,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randint(1, 1000, (2000, 2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have defined the `arr` *array*, you can use the DASK `from_array()` *function* to create a DASK *array*.\n",
    "\n",
    "## Question 2\n",
    "\n",
    "In the code cell below, set the value of the `chunks` *argument* to be equal to a *tuple* with elements equal to 250 and 250.\n",
    "\n",
    "This will divide the NumPy *array* into smaller *chunks*, each with dimensions 250 by 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "darr = da.from_array(arr, chunks=(250,250))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DASK also allows you to visualize a summary of the DASK *array* by *printing* it to screen.\n",
    "\n",
    "Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 15.26 MiB </td>\n",
       "                        <td> 244.14 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (2000, 2000) </td>\n",
       "                        <td> (250, 250) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 64 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> int32 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"15\" x2=\"120\" y2=\"15\" />\n",
       "  <line x1=\"0\" y1=\"30\" x2=\"120\" y2=\"30\" />\n",
       "  <line x1=\"0\" y1=\"45\" x2=\"120\" y2=\"45\" />\n",
       "  <line x1=\"0\" y1=\"60\" x2=\"120\" y2=\"60\" />\n",
       "  <line x1=\"0\" y1=\"75\" x2=\"120\" y2=\"75\" />\n",
       "  <line x1=\"0\" y1=\"90\" x2=\"120\" y2=\"90\" />\n",
       "  <line x1=\"0\" y1=\"105\" x2=\"120\" y2=\"105\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"15\" y1=\"0\" x2=\"15\" y2=\"120\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"120\" />\n",
       "  <line x1=\"45\" y1=\"0\" x2=\"45\" y2=\"120\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"120\" />\n",
       "  <line x1=\"75\" y1=\"0\" x2=\"75\" y2=\"120\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"120\" />\n",
       "  <line x1=\"105\" y1=\"0\" x2=\"105\" y2=\"120\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,120.0 0.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >2000</text>\n",
       "  <text x=\"140.000000\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,140.000000,60.000000)\">2000</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<array, shape=(2000, 2000), dtype=int32, chunksize=(250, 250), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "darr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "What can you observe from the result *printed* above? What is the size of each *chunk*? How many *chunks* is the NumPy *array* being divided into?\n",
    "\n",
    "This is an open-ended question that requires a written response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3: Dask converted the array into 64 smaller arrays. Each chunk is 244.14 kB. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to visualize the size of the *chunks* is by calling the DASK `chunksize()` *function*.\n",
    "\n",
    "Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 250)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "darr.chunksize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Similarly as you did in the previous code cell, call the `npartitions` *method* on the DASK *array* to *print* the number of partitions to screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "darr.npartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin comparing the performances of the NumPy and DASK *libraries* when performing operations on an *array*, you can start by computing the sum of all the entries across the rows of the *array*.\n",
    "\n",
    "## Question 5\n",
    "\n",
    "In the code cell below, set the `axis` *argument* equal to 0 to sum over the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = darr.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "In the code cell below, call the correct DASK *function* to visualize how each row is summed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 7.81 kiB </td>\n",
       "                        <td> 0.98 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (2000,) </td>\n",
       "                        <td> (250,) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 8 chunks in 4 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> int32 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"15\" y1=\"0\" x2=\"15\" y2=\"25\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"25\" />\n",
       "  <line x1=\"45\" y1=\"0\" x2=\"45\" y2=\"25\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"75\" y1=\"0\" x2=\"75\" y2=\"25\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"25\" />\n",
       "  <line x1=\"105\" y1=\"0\" x2=\"105\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >2000</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<sum-aggregate, shape=(2000,), dtype=int32, chunksize=(250,), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#res.visualize() #graphviz will not install\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "Summarize your observations of the graph produced in the previous code cell.\n",
    "\n",
    "This is an open-ended question that requires a written response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7: The graph shows each partition of the array being summed with another, and then those sums eventually being summed together as it moves up a branching tree to final the final sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, suppose that you want to perform some more advanced computations, such as computing the mean of the NumPy and DASK *arrays*.\n",
    "\n",
    "Run the code cell below to define the `numpy_mean()` and `dask_mean()` *functions* that compute the mean of the NumPy and DASK *arrays*, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_mean(size=(10, 10)):\n",
    "  arr = np.random.random(size=size)\n",
    "  return arr.mean()\n",
    "\n",
    "def dask_mean(size=(10, 10)):\n",
    "  if size[0] > 10000: chunks = (1000, 1000)\n",
    "  else: chunks = (int(size[0]/10), int(size[1]/10))\n",
    "  \n",
    "  arr = da.random.random(size=size, chunks=chunks)\n",
    "  y = arr.mean()\n",
    "  return y.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dask_arr_chk()` and `numpy_arr_chk` *functions* defined in the code cell below compute the mean of each *chunk* in the *arrays* and return the wall clock time used to complete the operations.\n",
    "\n",
    "Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def numpy_arr_chk():\n",
    "  sizes = []\n",
    "  times = []\n",
    "  size = 10\n",
    "  for i in range(4):\n",
    "    dim1 = size ** (i+1)\n",
    "    for j in range(4):\n",
    "      dim2 = size ** (j+1)\n",
    "      if dim1*dim2 in sizes: continue\n",
    "      st = time.time()\n",
    "      numpy_mean(size=(dim1, dim2))\n",
    "      en = time.time()\n",
    "      sizes.append(dim1*dim2)\n",
    "      times.append(en-st)\n",
    "  return times\n",
    "\n",
    "def dask_arr_chk():\n",
    "  sizes = []\n",
    "  times = []\n",
    "  size = 10\n",
    "  for i in range(5):\n",
    "    dim1 = size ** (i+1)\n",
    "    for j in range(4):\n",
    "      dim2 = size ** (j+1)\n",
    "      if dim1*dim2 in sizes: continue\n",
    "      st = time.time()\n",
    "      dask_mean(size=(dim1, dim2))\n",
    "      en = time.time()\n",
    "      sizes.append(dim1*dim2)\n",
    "      times.append(en-st)\n",
    "  return times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for you to compare the performances of NumPy and DASK *libraries* when computing parallel operations.\n",
    "\n",
    "## Question 8\n",
    "\n",
    "In the code below, call the `numpy_arr_chk()` *function* and assign the result to the `num_time` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 859 ms\n",
      "Wall time: 1.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_time = numpy_arr_chk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "\n",
    "In the code below, call the `dask_arr_chk()` *function* and assign the result to the `dask_time` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7.16 s\n",
      "Wall time: 4.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dask_time = dask_arr_chk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "\n",
    "Which *library* performs better, NumPy or DASK? Why?\n",
    "\n",
    "This is an open-ended question that requires a written response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 10: NumPy performed better because this task is not very complicated. The time it takes to initialize DASK does not outweigh the savings of parallelizing the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Pandas vs. DASK\n",
    "\n",
    "In the second part of the assignment, you will be comparing the performances of the pandas and DASK *libraries* when operating on a *dataframe* with just over 25,000,000 rows.\n",
    "\n",
    "Run the code cell below to import the necessary *libraries* for this part of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as ddf\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will begin by reading a dataset that contains information about the salary of data scientists in India.\n",
    "\n",
    "Because you want to compare the performance of the pandas and DASK *libraries*, you will start reading the data using the pandas *library*.\n",
    "\n",
    "Run the code cell below.\n",
    "\n",
    "Reference\n",
    "\n",
    "Banerjee, Sourav. \"Data Professionals Salary - 2022.\" Kaggle. 2022. https://www.kaggle.com/iamsouravbanerjee/analytics-industry-salaries-2022-india/version/9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Company Name                             Job Title  \\\n",
      "0                      Mu Sigma                        Data Scientist   \n",
      "1                           IBM                        Data Scientist   \n",
      "2     Tata Consultancy Services                        Data Scientist   \n",
      "3              Impact Analytics                        Data Scientist   \n",
      "4                     Accenture                        Data Scientist   \n",
      "...                         ...                                   ...   \n",
      "4339                    TaiyōAI            Machine Learning Scientist   \n",
      "4340    Decimal Point Analytics            Machine Learning Developer   \n",
      "4341                     MyWays            Machine Learning Developer   \n",
      "4342  Market Pulse Technologies  Software Engineer - Machine Learning   \n",
      "4343                    vPhrase             Machine Learning Engineer   \n",
      "\n",
      "      Salaries Reported   Location         Salary  \n",
      "0                 105.0  Bangalore   ₹6,48,573/yr  \n",
      "1                  95.0  Bangalore  ₹11,91,950/yr  \n",
      "2                  66.0  Bangalore   ₹8,36,874/yr  \n",
      "3                  40.0  Bangalore   ₹6,69,578/yr  \n",
      "4                  32.0  Bangalore   ₹9,44,110/yr  \n",
      "...                 ...        ...            ...  \n",
      "4339                1.0     Mumbai      ₹5,180/mo  \n",
      "4340                1.0     Mumbai   ₹7,51,286/yr  \n",
      "4341                1.0     Mumbai   ₹4,10,952/yr  \n",
      "4342                1.0     Mumbai  ₹16,12,324/yr  \n",
      "4343                1.0     Mumbai   ₹9,39,843/yr  \n",
      "\n",
      "[4344 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_pandas = pd.read_csv(r\"C:\\Users\\markg\\DataEngineering\\Module22\\FinalPt1\\salary.csv\")\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will read the same data using the DASK *library*.\n",
    "\n",
    "# Question 11\n",
    "\n",
    "Complete the code in the cell below to read the same dataset using DASK. Use the DASK `read_csv()` *function*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Company Name       Job Title  Salaries Reported   Location  \\\n",
      "0                   Mu Sigma  Data Scientist              105.0  Bangalore   \n",
      "1                        IBM  Data Scientist               95.0  Bangalore   \n",
      "2  Tata Consultancy Services  Data Scientist               66.0  Bangalore   \n",
      "3           Impact Analytics  Data Scientist               40.0  Bangalore   \n",
      "4                  Accenture  Data Scientist               32.0  Bangalore   \n",
      "\n",
      "          Salary  \n",
      "0   ₹6,48,573/yr  \n",
      "1  ₹11,91,950/yr  \n",
      "2   ₹8,36,874/yr  \n",
      "3   ₹6,69,578/yr  \n",
      "4   ₹9,44,110/yr  \n"
     ]
    }
   ],
   "source": [
    "df_dask = ddf.read_csv(\n",
    "    r\"C:\\Users\\markg\\DataEngineering\\Module22\\FinalPt1\\salary.csv\",\n",
    "    dtype={'Salaries Reported': 'float64'}  # Ensure 'Salaries Reported' is read as float64\n",
    ")\n",
    "print(df_dask.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also need to define the `benchmark()` *function* that will help you to compare the performance between the two *libraries*.\n",
    "\n",
    "Run the two code cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(function, function_name):\n",
    "    start = time.time()\n",
    "    function()\n",
    "    end = time.time()\n",
    "    print(\"{0} seconds for {1}\".format((end - start), function_name))\n",
    "\n",
    "def convert_pandas():\n",
    "    return(df_pandas)\n",
    "def convert_dask():\n",
    "    return(df_dask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can compare the performances for the two *dataframes*.\n",
    "\n",
    "Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 seconds for dataframe pandas\n",
      "0.0 seconds for dataframe DASK\n"
     ]
    }
   ],
   "source": [
    "benchmark(convert_pandas, 'dataframe pandas')\n",
    "benchmark(convert_dask, 'dataframe DASK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12\n",
    "\n",
    "Which *dataframe* takes longer? Why?\n",
    "\n",
    "This is an open-ended question that requires a written response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 12: DASK takes longer because it must set up the processors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, because the dataset is not large enough to make a meaningful comparison, you will concatenate the `df_pandas` and `df_dask` *dataframes* 5,000 times to increase the number of rows of data.\n",
    "\n",
    "Run the cell below to create the new *dataframes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas_big = pd.concat([df_pandas for _ in range(5000)])\n",
    "\n",
    "df_dask_big = pd.concat([df_pandas for _ in range(5000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, you will set up DASK to run in parallel.\n",
    "\n",
    "## Question 13\n",
    "\n",
    "Set the `npartition` *argument* inside of the `from_pandas` *function* equal to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = ddf.from_pandas(df_dask_big, npartitions=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, the necessary *functions* to compute the maximum value of the `Salary` column in the `dfn` and `df_pandas` *dataframes* are defined.\n",
    "\n",
    "The `run_benchmarks()` *function*, which is used to compare the performances on both *dataframes*, is also defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_big_max_dask():\n",
    "    return dfn.Salary.max().compute()\n",
    "def get_big_max_pandas():\n",
    "    return df_pandas.Salary.max()\n",
    "    \n",
    "def run_benchmarks():\n",
    "    for i,f in enumerate([get_big_max_dask]):benchmark(f, f.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to run the comparison between the `df_pandas_big` and `df_dask_big` *dataframes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.545953273773193 seconds for get_big_max_dask\n",
      "21.688851833343506 seconds for get_big_max_pandas\n"
     ]
    }
   ],
   "source": [
    "run_benchmarks()\n",
    "benchmark(get_big_max_dask, get_big_max_pandas.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 14\n",
    "\n",
    "Which *library* takes less time to run, pandas, or DASK? Why?\n",
    "\n",
    "This is an open-ended question and requires a written response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 14: DASK takes less because Pandas is slow in dealing with the Salary column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
